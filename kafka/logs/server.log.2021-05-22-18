[2021-05-22 18:01:53,359] WARN Client session timed out, have not heard from server in 15291ms for sessionid 0x1000000a8250000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:32,058] INFO Client session timed out, have not heard from server in 15291ms for sessionid 0x1000000a8250000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:36,332] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:37,925] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:41750, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:38,560] WARN Unable to reconnect to ZooKeeper service, session 0x1000000a8250000 has expired (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:38,572] INFO Unable to reconnect to ZooKeeper service, session 0x1000000a8250000 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:38,882] INFO EventThread shut down for session: 0x1000000a8250000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:39,009] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:02:39,081] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:02:39,081] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:02:39,120] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:02:39,162] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:39,755] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:39,912] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:41760, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:39,950] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:02:40,046] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000000a8250007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:02:43,955] INFO Updated cache from existing FinalizedFeaturesAndEpoch(features=Features{}, epoch=0) to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:02:44,226] INFO Stat of the created znode at /brokers/ids/0 is: 456,456,1621702960215,1621702960215,1,0,0,72057596858925063,202,0,456
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:02:44,321] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 456 (kafka.zk.KafkaZkClient)
[2021-05-22 18:03:23,119] WARN Client session timed out, have not heard from server in 12155ms for sessionid 0x1000000a8250007 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:03:23,125] INFO Client session timed out, have not heard from server in 12155ms for sessionid 0x1000000a8250007, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:03:30,651] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:03:43,180] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:41782, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:04:01,220] WARN Client session timed out, have not heard from server in 18049ms for sessionid 0x1000000a8250007 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:04:07,785] INFO Client session timed out, have not heard from server in 18049ms for sessionid 0x1000000a8250007, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:04:45,628] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:04:50,280] INFO Socket connection established, initiating session, client: /127.0.0.1:39240, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:05:11,002] WARN Client session timed out, have not heard from server in 20720ms for sessionid 0x1000000a8250007 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:05:13,056] INFO Client session timed out, have not heard from server in 20720ms for sessionid 0x1000000a8250007, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:05:41,069] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:06:09,799] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:41804, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:06:14,307] WARN Client session timed out, have not heard from server in 20187ms for sessionid 0x1000000a8250007 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:06:14,775] INFO Client session timed out, have not heard from server in 20187ms for sessionid 0x1000000a8250007, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:06:57,024] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:06:57,217] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:41816, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:07:16,430] WARN Client session timed out, have not heard from server in 18031ms for sessionid 0x1000000a8250007 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:07:17,017] INFO Client session timed out, have not heard from server in 18031ms for sessionid 0x1000000a8250007, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:39,514] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,567] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,617] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,617] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,688] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:15:39,688] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:15:39,695] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:15:39,695] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-05-22 18:15:39,748] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-05-22 18:15:39,943] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,943] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,951] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,959] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:15:39,959] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-05-22 18:15:40,016] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-05-22 18:15:40,184] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:15:40,195] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,200] INFO Server environment:host.name=rafael-pc (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,200] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,207] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,207] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,219] INFO Server environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,228] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,234] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,234] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,239] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,240] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,270] INFO Server environment:os.version=5.8.0-53-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,270] INFO Server environment:user.name=rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,270] INFO Server environment:user.home=/home/rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,271] INFO Server environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,275] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,275] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,278] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,312] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,314] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,319] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:15:40,510] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-05-22 18:15:40,558] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 4 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:15:40,629] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:15:40,636] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:455)
	at java.base/sun.nio.ch.Net.bind(Net.java:447)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-05-22 18:15:42,430] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:15:43,165] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:15:44,857] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:15:45,564] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:15:46,133] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:15:46,282] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:15:46,369] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:15:46,414] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:15:46,415] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:15:46,666] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:46,743] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,744] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,744] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,744] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,744] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,744] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,751] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,751] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,758] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,758] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,758] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,759] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,791] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:46,838] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:15:46,866] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:15:46,874] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:15:46,875] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:15:47,078] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,120] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:47,133] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:47,202] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,202] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,202] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,202] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,202] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,204] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,205] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,206] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,208] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,210] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,211] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,211] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,204] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,250] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:47,277] INFO Socket connection established, initiating session, client: /127.0.0.1:50480, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,338] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:15:47,383] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000000aee40000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,388] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:47,430] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,463] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:47,528] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,620] INFO Socket connection established, initiating session, client: /127.0.0.1:50482, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,695] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000000aee40001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:47,708] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:47,740] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:15:47,888] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:15:48,140] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:15:48,476] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:15:48,565] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:15:48,566] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:15:48,575] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:15:48,804] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:48,874] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,874] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,874] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,878] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,878] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,879] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,883] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,894] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,895] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,910] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,910] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,910] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,911] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,911] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,911] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,911] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,911] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,911] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:48,933] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:49,042] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:15:49,102] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:49,120] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:15:49,119] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:49,168] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:49,211] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:38294, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:49,277] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000000aee40002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:49,322] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:49,832] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:15:49,845] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:15:49,873] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:15:49,875] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:15:49,996] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:50,035] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,035] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,035] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,035] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,035] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,036] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,037] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,037] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,038] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,039] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,039] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,039] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,066] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:50,117] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:15:50,167] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:50,185] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:50,220] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:50,274] INFO Socket connection established, initiating session, client: /127.0.0.1:50486, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:50,305] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000000aee40003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:50,327] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:15:50,339] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:15:50,343] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:50,355] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:15:50,524] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:15:50,618] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:15:50,637] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:15:50,671] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:15:50,821] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:15:50,834] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:50,910] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:51,199] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:51,279] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:51,336] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:15:51,359] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:15:51,387] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:15:51,380] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,393] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,422] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,425] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,561] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:15:51,568] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:15:51,573] WARN No meta.properties file under dir /tmp/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:15:51,647] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:51,613] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,654] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,660] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,680] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,680] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,689] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,692] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,692] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,693] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,696] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,697] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,698] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,698] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,698] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,698] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,698] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,724] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,725] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,730] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,730] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,730] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,735] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:51,799] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:15:51,893] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:51,893] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:51,985] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:52,054] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:52,086] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:52,122] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:15:52,126] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:15:52,136] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:38298, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:52,181] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:52,166] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2021-05-22 18:15:52,199] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:15:52,200] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2021-05-22 18:15:52,223] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:15:52,263] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:15:52,306] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000000aee40004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:52,312] INFO Loaded 0 logs in 121ms. (kafka.log.LogManager)
[2021-05-22 18:15:52,328] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:52,370] INFO Loaded 0 logs in 152ms. (kafka.log.LogManager)
[2021-05-22 18:15:52,496] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:15:52,527] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:15:52,532] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:15:52,580] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:15:52,668] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:52,706] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:52,710] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:52,778] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:15:52,797] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:15:52,800] WARN No meta.properties file under dir /tmp/kafka-logs-5/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:15:53,098] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:15:53,125] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:53,170] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:15:53,184] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:15:53,233] INFO Log directory /tmp/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:15:53,234] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:53,267] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:53,315] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2021-05-22 18:15:53,341] INFO Attempting recovery for all logs in /tmp/kafka-logs-3 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:15:53,384] INFO Loaded 0 logs in 62ms. (kafka.log.LogManager)
[2021-05-22 18:15:53,434] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:53,515] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:15:53,533] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:15:53,563] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:15:53,589] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,594] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,594] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,595] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,595] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,595] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,597] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,597] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,597] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,603] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,604] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,606] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,613] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:15:53,707] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:15:53,750] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:53,754] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:53,761] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:53,781] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:53,801] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:53,869] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:53,926] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:53,980] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:38300, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:54,030] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000000aee40005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:15:54,044] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:15:54,264] INFO Log directory /tmp/kafka-logs-5 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:15:54,298] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2021-05-22 18:15:54,306] INFO Attempting recovery for all logs in /tmp/kafka-logs-5 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:15:54,332] INFO Loaded 0 logs in 34ms. (kafka.log.LogManager)
[2021-05-22 18:15:54,516] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:15:54,577] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:15:54,683] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:15:55,596] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:15:55,603] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:15:55,628] WARN No meta.properties file under dir /tmp/kafka-logs-4/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:15:56,126] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9096
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:56,170] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9096
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:56,409] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:56,447] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:56,449] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:56,446] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:56,858] INFO Log directory /tmp/kafka-logs-4 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:15:56,902] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2021-05-22 18:15:56,906] INFO Attempting recovery for all logs in /tmp/kafka-logs-4 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:15:56,941] INFO Loaded 0 logs in 39ms. (kafka.log.LogManager)
[2021-05-22 18:15:57,100] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:15:57,104] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:15:57,114] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:15:57,116] WARN No meta.properties file under dir /tmp/kafka-logs-6/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:15:57,159] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:15:57,398] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9098
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9098
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:57,450] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9098
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9098
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:15:57,740] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:57,790] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:57,791] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:57,790] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:15:58,202] INFO Log directory /tmp/kafka-logs-6 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:15:58,240] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-6) (kafka.log.LogManager)
[2021-05-22 18:15:58,258] INFO Attempting recovery for all logs in /tmp/kafka-logs-6 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:15:58,291] INFO Loaded 0 logs in 41ms. (kafka.log.LogManager)
[2021-05-22 18:15:58,386] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:15:58,427] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:16:01,682] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:01,686] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:01,762] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:01,770] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2021-05-22 18:16:01,574] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:01,872] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:01,912] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:01,946] INFO Awaiting socket connections on localhost:9097. (kafka.network.Acceptor)
[2021-05-22 18:16:02,066] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,145] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,210] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:02,237] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,252] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2021-05-22 18:16:02,195] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,395] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,403] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,421] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2021-05-22 18:16:02,474] INFO [SocketServer brokerId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:02,605] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,622] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,669] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,532] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,687] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,699] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,776] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:02,803] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,766] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:02,870] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,839] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,794] INFO Awaiting socket connections on localhost:9096. (kafka.network.Acceptor)
[2021-05-22 18:16:02,923] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:02,965] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:03,051] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:16:03,091] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:03,210] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:16:03,210] INFO [broker-4-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:03,205] INFO [SocketServer brokerId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:03,259] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,260] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,272] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,276] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,260] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,301] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,366] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,366] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,381] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:16:03,406] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:03,499] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:03,489] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:03,540] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:03,574] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:16:03,596] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,615] INFO Stat of the created znode at /brokers/ids/4 is: 557,557,1621703763590,1621703763590,1,0,0,72057596972105731,202,0,557
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:03,616] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://localhost:9097, czxid (broker epoch): 557 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:03,622] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,618] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,632] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:03,603] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:03,580] INFO Awaiting socket connections on localhost:9098. (kafka.network.Acceptor)
[2021-05-22 18:16:03,709] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:16:03,710] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:03,785] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:16:03,802] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:03,954] INFO Stat of the created znode at /brokers/ids/0 is: 558,558,1621703763883,1621703763883,1,0,0,72057596972105728,202,0,558
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:03,956] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 558 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,019] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,084] INFO [SocketServer brokerId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:04,117] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,119] INFO Stat of the created znode at /brokers/ids/1 is: 559,559,1621703764109,1621703764109,1,0,0,72057596972105729,202,0,559
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,120] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 559 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,202] INFO Stat of the created znode at /brokers/ids/2 is: 560,560,1621703764187,1621703764187,1,0,0,72057596972105730,202,0,560
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,203] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9095, czxid (broker epoch): 560 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,279] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,396] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,436] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,592] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,699] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,714] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,806] INFO Stat of the created znode at /brokers/ids/3 is: 562,562,1621703764788,1621703764788,1,0,0,72057596972105732,202,0,562
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,828] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,847] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://localhost:9096, czxid (broker epoch): 562 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:04,884] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,916] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,924] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,986] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:04,988] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:04,988] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:04,997] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,028] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,081] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,119] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,119] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,123] INFO [ProducerId Manager 4]: Acquired new producerId block (brokerId:4,blockStartProducerId:18000,blockEndProducerId:18999) by writing to Zk with path version 19 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:16:05,093] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,158] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,137] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,289] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:19000,blockEndProducerId:19999) by writing to Zk with path version 20 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:16:05,303] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:16:05,304] INFO [broker-5-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:05,294] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:05,331] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,338] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,367] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,394] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,414] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:05,451] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:16:05,638] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:05,632] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:20000,blockEndProducerId:20999) by writing to Zk with path version 21 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:16:05,671] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,686] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:05,694] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:16:05,698] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:21000,blockEndProducerId:21999) by writing to Zk with path version 22 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:16:05,718] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:05,851] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,855] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,891] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:05,897] INFO Stat of the created znode at /brokers/ids/5 is: 568,568,1621703765847,1621703765847,1,0,0,72057596972105733,202,0,568
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:05,898] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://localhost:9098, czxid (broker epoch): 568 (kafka.zk.KafkaZkClient)
[2021-05-22 18:16:05,920] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:05,936] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:06,024] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:06,040] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:06,049] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:06,088] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:16:06,090] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:06,099] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:16:06,167] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:06,243] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:16:06,225] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:22000,blockEndProducerId:22999) by writing to Zk with path version 23 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:16:06,306] INFO [SocketServer brokerId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,382] INFO [SocketServer brokerId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:06,384] INFO [SocketServer brokerId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,418] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:16:06,471] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:06,491] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,491] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,491] INFO Kafka startTimeMs: 1621703766384 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,493] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2021-05-22 18:16:06,498] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:06,634] INFO [SocketServer brokerId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,638] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:06,684] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:06,757] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:16:06,809] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:16:06,821] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:16:06,845] INFO [SocketServer brokerId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:06,848] INFO [SocketServer brokerId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,856] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,878] INFO [SocketServer brokerId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,911] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:06,912] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:06,935] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,940] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,940] INFO Kafka startTimeMs: 1621703766913 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,942] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-05-22 18:16:06,986] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,987] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,987] INFO Kafka startTimeMs: 1621703766850 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:06,998] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2021-05-22 18:16:07,042] INFO [broker-4-to-controller-send-thread]: Recorded new controller, from now on will use broker 4 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:07,143] INFO [SocketServer brokerId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:07,144] INFO [SocketServer brokerId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:07,151] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:07,151] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:07,152] INFO Kafka startTimeMs: 1621703767145 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:07,173] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:07,153] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2021-05-22 18:16:07,187] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:07,211] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:07,211] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:07,290] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:07,294] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:16:07,332] INFO [ProducerId Manager 5]: Acquired new producerId block (brokerId:5,blockStartProducerId:23000,blockEndProducerId:23999) by writing to Zk with path version 24 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:16:07,339] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker 4 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:07,472] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:07,476] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:16:07,487] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 4 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:07,623] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:16:07,639] INFO [SocketServer brokerId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:07,672] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker 4 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:07,727] INFO [SocketServer brokerId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:07,728] INFO [SocketServer brokerId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:07,753] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:07,754] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:07,754] INFO Kafka startTimeMs: 1621703767728 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:07,755] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:16:07,799] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2021-05-22 18:16:07,873] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:16:08,004] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker 4 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:16:08,621] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:16:08,641] INFO [SocketServer brokerId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:08,678] INFO [SocketServer brokerId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:16:08,679] INFO [SocketServer brokerId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:16:08,765] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:08,774] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:08,774] INFO Kafka startTimeMs: 1621703768680 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:16:08,780] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2021-05-22 18:16:08,867] INFO [broker-5-to-controller-send-thread]: Recorded new controller, from now on will use broker 4 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:01,005] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,022] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,052] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,052] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,066] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:22:01,067] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:22:01,067] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:22:01,067] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-05-22 18:22:01,104] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-05-22 18:22:01,296] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,303] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,303] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,304] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:22:01,304] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-05-22 18:22:01,322] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-05-22 18:22:01,445] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,445] INFO Server environment:host.name=rafael-pc (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,445] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,445] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,445] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,446] INFO Server environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,464] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,464] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,464] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,465] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,465] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,465] INFO Server environment:os.version=5.8.0-53-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,465] INFO Server environment:user.name=rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,465] INFO Server environment:user.home=/home/rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,465] INFO Server environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,467] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,468] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,474] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,510] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,510] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,511] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:22:01,618] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-05-22 18:22:01,659] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 4 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:22:01,736] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:22:01,751] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:455)
	at java.base/sun.nio.ch.Net.bind(Net.java:447)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-05-22 18:22:03,318] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:22:03,731] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:22:05,618] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:22:07,380] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:22:08,105] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:22:08,110] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:22:08,163] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:22:08,735] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:22:08,784] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:22:08,796] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:22:08,802] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:22:08,835] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:22:08,840] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:22:09,071] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:09,084] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:09,134] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,134] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,134] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,134] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,135] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,139] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,140] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,140] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,141] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,141] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,147] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,147] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,148] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,148] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,148] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,148] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,148] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,149] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,190] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,200] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,200] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,200] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,200] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,200] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,215] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,215] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,215] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,216] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,216] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,218] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,219] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,218] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,227] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,227] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,227] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,240] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,241] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,261] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:22:09,289] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:09,291] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,312] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:09,363] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,382] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:22:09,366] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:22:09,432] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:46456, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,479] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,531] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:09,534] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000007de40000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,538] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:09,600] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,623] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:46458, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,662] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000007de40001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:09,665] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:09,723] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:22:09,801] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:22:09,825] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:22:09,852] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:22:10,055] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:22:10,132] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:22:10,138] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:10,153] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,155] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,155] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,155] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,155] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,156] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,157] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,157] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,157] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,158] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,160] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,160] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,160] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,160] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,161] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,161] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,161] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,161] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,164] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:10,217] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:22:10,260] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:10,314] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:10,367] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:10,388] INFO Socket connection established, initiating session, client: /127.0.0.1:44442, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:10,425] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000007de40002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:10,434] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:10,712] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:22:10,721] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:22:11,198] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:22:11,313] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:22:11,319] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:22:11,336] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:22:11,558] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:11,596] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:22:11,611] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:22:11,615] WARN No meta.properties file under dir /tmp/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:22:11,641] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:22:11,653] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:22:11,656] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:22:11,663] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,663] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,663] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,663] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,663] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,663] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,664] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,686] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,689] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,691] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:11,758] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:22:11,779] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:11,829] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:22:11,857] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:22:11,850] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:11,859] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:22:11,854] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:22:11,876] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:22:11,880] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:22:11,878] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:11,943] INFO Socket connection established, initiating session, client: /127.0.0.1:44444, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:12,015] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000007de40003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:12,019] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:12,066] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:12,067] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:12,110] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:12,157] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:12,122] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,184] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,185] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,185] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,185] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,190] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,191] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,191] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,191] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,192] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,192] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,192] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,175] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:12,230] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,230] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,230] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,230] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,230] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,231] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,258] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:12,271] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:22:12,292] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:12,330] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:22:12,400] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:12,399] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:12,446] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:12,513] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:12,556] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:22:12,635] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:46464, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:12,669] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,685] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,700] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000007de40004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:12,680] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,689] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,715] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,723] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:12,727] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,732] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,739] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,692] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,707] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,772] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,772] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:12,997] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:22:13,040] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:22:13,056] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:22:13,089] INFO Log directory /tmp/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:22:13,138] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2021-05-22 18:22:13,155] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2021-05-22 18:22:13,158] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:22:13,196] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:22:13,195] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:22:13,194] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:22:13,192] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2021-05-22 18:22:13,187] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:22:13,244] INFO Attempting recovery for all logs in /tmp/kafka-logs-3 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:22:13,253] INFO Loaded 0 logs in 103ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,243] INFO Loaded 0 logs in 60ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,295] INFO Loaded 0 logs in 70ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,429] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,457] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,468] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:13,483] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,487] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,505] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,512] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:22:13,520] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,531] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,535] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,535] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,535] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,535] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,536] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,538] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,538] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,538] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,538] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,538] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,539] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,539] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,539] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,539] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,539] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,539] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,545] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:22:13,617] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:22:13,623] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:13,639] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:13,687] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:13,713] INFO Socket connection established, initiating session, client: /127.0.0.1:44448, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:13,764] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000007de40005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:22:13,770] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:22:13,994] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:22:13,999] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:22:14,002] WARN No meta.properties file under dir /tmp/kafka-logs-4/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:22:14,284] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:22:14,392] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9096
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:14,534] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9096
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:14,692] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:22:14,698] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:22:14,701] WARN No meta.properties file under dir /tmp/kafka-logs-5/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:22:14,873] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:14,875] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:14,900] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:15,017] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:15,037] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:15,089] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:15,144] INFO Log directory /tmp/kafka-logs-4 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:22:15,237] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2021-05-22 18:22:15,257] INFO Attempting recovery for all logs in /tmp/kafka-logs-4 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:22:15,310] INFO Loaded 0 logs in 56ms. (kafka.log.LogManager)
[2021-05-22 18:22:15,389] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:22:15,446] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:15,491] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:22:15,492] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:15,492] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:15,540] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:15,634] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:22:15,746] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:22:15,750] WARN No meta.properties file under dir /tmp/kafka-logs-6/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:22:15,810] INFO Log directory /tmp/kafka-logs-5 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:22:15,899] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2021-05-22 18:22:15,916] INFO Attempting recovery for all logs in /tmp/kafka-logs-5 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:22:15,927] INFO Loaded 0 logs in 20ms. (kafka.log.LogManager)
[2021-05-22 18:22:15,990] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:22:15,994] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:22:16,028] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9098
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9098
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:16,160] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9098
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9098
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:22:16,605] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:16,895] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:16,895] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:16,895] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:22:17,033] INFO Log directory /tmp/kafka-logs-6 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:22:17,064] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-6) (kafka.log.LogManager)
[2021-05-22 18:22:17,078] INFO Attempting recovery for all logs in /tmp/kafka-logs-6 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:22:17,176] INFO Loaded 0 logs in 100ms. (kafka.log.LogManager)
[2021-05-22 18:22:16,808] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:17,301] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:17,304] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:17,236] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:22:17,330] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:22:17,357] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2021-05-22 18:22:17,687] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:17,980] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:17,986] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:18,005] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,014] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:18,062] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,062] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,068] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,081] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2021-05-22 18:22:18,209] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:18,222] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:18,291] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:22:18,272] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:18,298] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:18,332] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2021-05-22 18:22:18,583] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:18,680] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:18,878] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,914] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:18,955] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,955] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,965] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:18,972] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:19,034] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:19,034] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:19,034] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:19,217] INFO Stat of the created znode at /brokers/ids/0 is: 662,662,1621704139023,1621704139023,1,0,0,72057596150022145,202,0,662
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:19,221] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 662 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:19,363] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:22:19,376] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:19,384] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:22:19,391] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:19,481] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:19,486] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:19,499] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:19,504] INFO Awaiting socket connections on localhost:9097. (kafka.network.Acceptor)
[2021-05-22 18:22:19,190] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:19,647] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:19,680] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:19,713] INFO Awaiting socket connections on localhost:9096. (kafka.network.Acceptor)
[2021-05-22 18:22:19,818] INFO [SocketServer brokerId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:20,072] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:20,067] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:20,094] INFO [SocketServer brokerId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:20,189] INFO Stat of the created znode at /brokers/ids/2 is: 663,663,1621704140176,1621704140176,1,0,0,72057596150022146,202,0,663
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:20,191] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9095, czxid (broker epoch): 663 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:20,286] INFO Stat of the created znode at /brokers/ids/1 is: 664,664,1621704140256,1621704140256,1,0,0,72057596150022144,202,0,664
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:20,288] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 664 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:20,315] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,321] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,361] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,315] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,365] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,369] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,375] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,366] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,383] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,467] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,474] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:20,590] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:22:20,592] INFO [broker-4-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:20,729] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:20,736] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:20,791] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:22:20,812] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:20,888] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:24000,blockEndProducerId:24999) by writing to Zk with path version 25 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:22:21,005] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,102] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,102] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,235] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:21,280] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,328] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,334] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:21,352] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:22:21,416] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,474] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:21,479] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:21,532] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:21,607] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:21,606] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:21,665] INFO Stat of the created znode at /brokers/ids/4 is: 667,667,1621704141611,1621704141611,1,0,0,72057596150022148,202,0,667
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:21,667] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://localhost:9097, czxid (broker epoch): 667 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:21,680] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:21,744] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:25000,blockEndProducerId:25999) by writing to Zk with path version 26 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:22:21,823] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:21,844] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:26000,blockEndProducerId:26999) by writing to Zk with path version 27 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:22:21,871] INFO Stat of the created znode at /brokers/ids/3 is: 669,669,1621704141797,1621704141797,1,0,0,72057596150022147,202,0,669
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:21,875] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://localhost:9096, czxid (broker epoch): 669 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:22,022] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:22,127] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:22,149] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:22,202] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:22,225] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:22:22,245] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:22:22,341] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:22,344] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:22,420] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:22:22,442] INFO Awaiting socket connections on localhost:9098. (kafka.network.Acceptor)
[2021-05-22 18:22:22,496] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,535] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,606] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,611] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,799] INFO [SocketServer brokerId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:22,858] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,913] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,913] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,921] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,943] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,953] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:22,993] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:22:23,022] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:23,034] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:23,041] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:23,062] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:23,066] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:22:23,114] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:22:23,128] INFO [broker-5-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:23,121] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:22:23,068] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:23,160] INFO [SocketServer brokerId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:23,153] INFO [SocketServer brokerId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:23,233] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:23,235] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:23,262] INFO [SocketServer brokerId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:23,265] INFO [SocketServer brokerId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:23,272] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:27000,blockEndProducerId:27999) by writing to Zk with path version 28 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:22:23,370] INFO [SocketServer brokerId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:23,371] INFO [SocketServer brokerId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:23,435] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:23,455] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,493] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,493] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,493] INFO Kafka startTimeMs: 1621704143265 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,501] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,501] INFO Kafka startTimeMs: 1621704143371 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,433] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,516] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,522] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2021-05-22 18:22:23,528] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:23,516] INFO Kafka startTimeMs: 1621704143244 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:23,514] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2021-05-22 18:22:23,567] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-05-22 18:22:23,481] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:23,908] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:23,923] INFO [ProducerId Manager 4]: Acquired new producerId block (brokerId:4,blockStartProducerId:28000,blockEndProducerId:28999) by writing to Zk with path version 29 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:22:23,940] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:23,934] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:23,980] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:22:24,014] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:24,053] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:24,117] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:24,121] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:24,137] INFO Stat of the created znode at /brokers/ids/5 is: 675,675,1621704144102,1621704144102,1,0,0,72057596150022149,202,0,675
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:24,150] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://localhost:9098, czxid (broker epoch): 675 (kafka.zk.KafkaZkClient)
[2021-05-22 18:22:24,176] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:22:24,317] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:24,399] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:22:24,414] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:24,418] INFO [SocketServer brokerId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:24,492] INFO [SocketServer brokerId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:24,493] INFO [SocketServer brokerId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:24,509] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:24,516] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:24,517] INFO Kafka startTimeMs: 1621704144500 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:24,518] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2021-05-22 18:22:24,616] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:22:24,667] INFO [SocketServer brokerId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:24,754] INFO [SocketServer brokerId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:24,749] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:24,756] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:24,745] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:24,771] INFO [SocketServer brokerId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:24,817] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:24,874] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:24,877] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:24,878] INFO Kafka startTimeMs: 1621704144816 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:24,917] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2021-05-22 18:22:24,927] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:24,933] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:22:24,971] INFO [ProducerId Manager 5]: Acquired new producerId block (brokerId:5,blockStartProducerId:29000,blockEndProducerId:29999) by writing to Zk with path version 30 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:22:25,133] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:25,156] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:22:25,213] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:22:25,228] INFO [broker-4-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:22:25,266] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:22:25,325] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:22:25,331] INFO [SocketServer brokerId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:25,353] INFO [SocketServer brokerId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:22:25,354] INFO [SocketServer brokerId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:22:25,364] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:25,365] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:25,365] INFO Kafka startTimeMs: 1621704145355 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:22:25,367] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2021-05-22 18:22:25,437] INFO [broker-5-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:24:39,743] WARN Client session timed out, have not heard from server in 18702ms for sessionid 0x10000007de40001 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:39,804] INFO Client session timed out, have not heard from server in 18702ms for sessionid 0x10000007de40001, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:49,951] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:50,853] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:46480, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:52,309] WARN Unable to reconnect to ZooKeeper service, session 0x10000007de40001 has expired (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:53,030] INFO Unable to reconnect to ZooKeeper service, session 0x10000007de40001 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:53,410] INFO EventThread shut down for session: 0x10000007de40001 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:24:53,985] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:25:09,068] WARN Client session timed out, have not heard from server in 13415ms for sessionid 0x10000007de40003 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:25:09,059] WARN Client session timed out, have not heard from server in 12537ms for sessionid 0x10000007de40002 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:25:09,683] WARN Client session timed out, have not heard from server in 13726ms for sessionid 0x10000007de40004 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:25:10,035] INFO Client session timed out, have not heard from server in 13726ms for sessionid 0x10000007de40004, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:25:14,924] INFO Client session timed out, have not heard from server in 13415ms for sessionid 0x10000007de40003, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:25:19,217] INFO Client session timed out, have not heard from server in 12537ms for sessionid 0x10000007de40002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:28,105] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,161] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,261] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,272] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,350] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:33:28,350] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:33:28,351] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:33:28,352] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-05-22 18:33:28,472] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-05-22 18:33:28,660] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,661] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,663] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,669] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:33:28,670] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-05-22 18:33:28,728] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-05-22 18:33:28,877] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,881] INFO Server environment:host.name=rafael-pc (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,881] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,881] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,881] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,881] INFO Server environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,884] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,888] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,889] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,889] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,890] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,896] INFO Server environment:os.version=5.8.0-53-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,896] INFO Server environment:user.name=rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,896] INFO Server environment:user.home=/home/rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,896] INFO Server environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,898] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,898] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,898] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,923] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,924] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:28,925] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:33:29,137] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-05-22 18:33:29,182] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 4 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:33:29,249] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:33:29,251] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:455)
	at java.base/sun.nio.ch.Net.bind(Net.java:447)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-05-22 18:33:31,771] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:33:32,924] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:33:33,973] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:33:34,565] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:33:35,485] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:33:36,594] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:33:36,693] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:33:36,714] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:33:37,231] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:33:37,222] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:33:37,266] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:33:37,268] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:33:37,287] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:33:37,289] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:33:37,481] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:37,488] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:37,542] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,543] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,543] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,543] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,543] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,544] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,547] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,547] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,548] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,549] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,571] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,589] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:33:37,600] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,611] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,611] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,620] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,620] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,621] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,626] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,627] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,627] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,627] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,627] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,634] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,635] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,635] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,635] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,635] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,635] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,635] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,641] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:33:37,661] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:37,727] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:37,744] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:33:37,760] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:37,840] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:37,875] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:37,847] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:37,911] INFO Socket connection established, initiating session, client: /127.0.0.1:41706, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:37,951] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:37,979] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000008ad30000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:37,985] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:38,080] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:34132, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:38,107] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000008ad30001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:38,120] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:38,287] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:33:38,513] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:33:38,581] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:33:38,624] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:33:38,644] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:33:38,645] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:33:38,676] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:33:38,730] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:38,712] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:33:38,739] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,741] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,741] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,742] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:33:38,741] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,745] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,745] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,746] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,746] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,757] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,760] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,785] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:33:38,809] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:38,817] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:38,913] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:38,926] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,948] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,948] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,949] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,949] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,945] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:38,953] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,956] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,956] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,957] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,958] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,959] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,964] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:38,987] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:34134, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:39,007] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:33:39,054] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000008ad30002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:39,058] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:39,138] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:39,164] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:39,185] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:39,211] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:34136, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:39,229] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000008ad30003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:39,238] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:39,448] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:33:39,479] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:33:39,657] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:33:39,683] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:33:39,860] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:33:39,898] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:33:39,931] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:33:39,857] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:33:40,047] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:33:40,050] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:40,055] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:33:40,078] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,078] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,078] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,078] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,078] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,078] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,079] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,080] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,082] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,116] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:33:40,140] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:40,147] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,150] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,151] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,151] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,151] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,152] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,152] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,153] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,153] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,153] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,154] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,155] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,156] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,156] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,156] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,156] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,157] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,180] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,180] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,203] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:33:40,232] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:40,233] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:33:40,270] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,279] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,276] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:34138, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,295] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:33:40,304] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:40,332] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:33:40,342] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:33:40,349] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:33:40,350] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000008ad30004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,360] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:33:40,371] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:40,388] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:33:40,367] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,424] INFO Socket connection established, initiating session, client: /127.0.0.1:41716, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,506] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000008ad30005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:33:40,514] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:33:40,596] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:33:40,608] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:33:40,614] WARN No meta.properties file under dir /tmp/kafka-logs-4/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:33:40,896] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:33:40,904] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:33:40,907] WARN No meta.properties file under dir /tmp/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:33:41,000] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:33:41,032] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,077] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:33:41,100] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,112] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,183] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,231] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9096
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,333] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9096
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,439] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,456] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,482] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,528] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,481] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,538] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,531] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,541] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,634] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:41,512] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,819] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:33:41,820] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:33:41,850] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2021-05-22 18:33:41,941] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,907] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2021-05-22 18:33:41,966] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:33:41,968] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:33:41,846] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:42,014] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,916] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,916] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:42,041] INFO Loaded 0 logs in 133ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,107] INFO Loaded 0 logs in 146ms. (kafka.log.LogManager)
[2021-05-22 18:33:41,952] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:42,105] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:41,979] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:42,089] INFO Log directory /tmp/kafka-logs-4 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:33:42,234] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,264] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,271] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,273] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,308] INFO Log directory /tmp/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:33:42,311] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2021-05-22 18:33:42,361] INFO Attempting recovery for all logs in /tmp/kafka-logs-4 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:33:42,445] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2021-05-22 18:33:42,461] INFO Loaded 0 logs in 150ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,471] INFO Attempting recovery for all logs in /tmp/kafka-logs-3 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:33:42,523] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:33:42,521] INFO Loaded 0 logs in 76ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,535] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:33:42,575] WARN No meta.properties file under dir /tmp/kafka-logs-5/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:33:42,601] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,627] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,649] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,701] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:33:42,782] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:33:42,791] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:33:42,793] WARN No meta.properties file under dir /tmp/kafka-logs-6/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:33:43,219] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9098
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9098
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:43,228] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:43,300] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9098
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9098
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:43,325] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:33:43,643] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,662] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,720] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,578] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,760] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,625] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,757] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,757] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:33:43,920] INFO Log directory /tmp/kafka-logs-6 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:33:43,922] INFO Log directory /tmp/kafka-logs-5 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:33:43,967] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2021-05-22 18:33:43,964] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-6) (kafka.log.LogManager)
[2021-05-22 18:33:43,990] INFO Attempting recovery for all logs in /tmp/kafka-logs-6 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:33:44,017] INFO Attempting recovery for all logs in /tmp/kafka-logs-5 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:33:44,090] INFO Loaded 0 logs in 103ms. (kafka.log.LogManager)
[2021-05-22 18:33:44,102] INFO Loaded 0 logs in 133ms. (kafka.log.LogManager)
[2021-05-22 18:33:44,176] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:33:44,227] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:33:44,292] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:33:44,338] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:33:45,975] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,012] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,069] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,152] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2021-05-22 18:33:46,183] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,192] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,188] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,208] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,224] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,261] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2021-05-22 18:33:46,339] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,357] INFO Awaiting socket connections on localhost:9096. (kafka.network.Acceptor)
[2021-05-22 18:33:46,318] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,402] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,425] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:46,430] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2021-05-22 18:33:46,591] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:46,574] INFO [SocketServer brokerId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:46,795] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:46,730] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:47,059] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,074] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:47,126] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,145] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:47,165] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,172] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,165] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,201] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,211] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,213] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,219] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,227] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,225] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,345] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:47,350] INFO Awaiting socket connections on localhost:9097. (kafka.network.Acceptor)
[2021-05-22 18:33:47,235] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,347] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,236] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,358] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,364] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:47,335] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:47,441] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:47,476] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:33:47,484] INFO [broker-3-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:47,486] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:33:47,544] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:33:47,544] INFO [broker-2-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:47,563] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:33:47,564] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:47,562] INFO Awaiting socket connections on localhost:9098. (kafka.network.Acceptor)
[2021-05-22 18:33:47,576] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:33:47,579] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:47,765] INFO [SocketServer brokerId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:47,930] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:47,943] INFO [SocketServer brokerId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:48,140] INFO Stat of the created znode at /brokers/ids/1 is: 770,770,1621704828093,1621704828093,1,0,0,72057596367011841,202,0,770
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,141] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 770 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,150] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,183] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,180] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,266] INFO Stat of the created znode at /brokers/ids/2 is: 771,771,1621704828248,1621704828248,1,0,0,72057596367011843,202,0,771
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,270] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9095, czxid (broker epoch): 771 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,281] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,305] INFO Stat of the created znode at /brokers/ids/0 is: 772,772,1621704828262,1621704828262,1,0,0,72057596367011840,202,0,772
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,307] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 772 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,184] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,312] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,224] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,424] INFO [broker-4-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:48,422] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:33:48,480] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,462] INFO Stat of the created znode at /brokers/ids/3 is: 773,773,1621704828408,1621704828408,1,0,0,72057596367011842,202,0,773
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,486] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://localhost:9096, czxid (broker epoch): 773 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,527] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,559] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,567] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:48,751] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:33:48,752] INFO [broker-5-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:48,772] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:48,994] INFO Stat of the created znode at /brokers/ids/4 is: 774,774,1621704828967,1621704828967,1,0,0,72057596367011844,202,0,774
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:49,018] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://localhost:9097, czxid (broker epoch): 774 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:49,228] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,312] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,332] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,338] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,365] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,368] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,363] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,397] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,481] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,486] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:49,608] INFO Stat of the created znode at /brokers/ids/5 is: 776,776,1621704829579,1621704829579,1,0,0,72057596367011845,202,0,776
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:49,612] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,633] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://localhost:9098, czxid (broker epoch): 776 (kafka.zk.KafkaZkClient)
[2021-05-22 18:33:49,667] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,670] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:49,741] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,752] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,757] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,802] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,862] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,885] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,904] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:30000,blockEndProducerId:30999) by writing to Zk with path version 31 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:33:49,925] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:31000,blockEndProducerId:31999) by writing to Zk with path version 32 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:33:49,875] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,972] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:49,984] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:32000,blockEndProducerId:32999) by writing to Zk with path version 33 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:33:50,023] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,026] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,041] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:33:50,200] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,220] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:33000,blockEndProducerId:33999) by writing to Zk with path version 34 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:33:50,127] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,252] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,269] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,330] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,361] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:33:50,364] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,394] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,400] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,415] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,425] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:33:50,449] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:50,462] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:33:50,715] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,724] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:50,749] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:50,765] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,772] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,809] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:33:50,824] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,833] INFO [SocketServer brokerId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:50,849] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:33:50,857] INFO [SocketServer brokerId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:50,858] INFO [SocketServer brokerId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:50,905] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,906] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:50,889] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:50,902] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:33:50,946] INFO [SocketServer brokerId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:51,046] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:51,047] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:51,034] INFO [ProducerId Manager 4]: Acquired new producerId block (brokerId:4,blockStartProducerId:34000,blockEndProducerId:34999) by writing to Zk with path version 35 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:33:51,111] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:33:51,115] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,121] INFO [SocketServer brokerId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:51,133] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,144] INFO [SocketServer brokerId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:51,147] INFO [SocketServer brokerId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:51,134] INFO Kafka startTimeMs: 1621704831047 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,119] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,173] INFO [SocketServer brokerId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:51,153] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,175] INFO [SocketServer brokerId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:51,175] INFO Kafka startTimeMs: 1621704830858 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,177] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2021-05-22 18:33:51,216] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-05-22 18:33:51,355] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,355] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,356] INFO Kafka startTimeMs: 1621704831148 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,358] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2021-05-22 18:33:51,382] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:51,420] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,421] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,421] INFO Kafka startTimeMs: 1621704831177 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:51,431] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:51,437] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2021-05-22 18:33:51,460] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:33:51,563] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:51,604] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:33:51,746] INFO [broker-2-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:51,759] INFO [ProducerId Manager 5]: Acquired new producerId block (brokerId:5,blockStartProducerId:35000,blockEndProducerId:35999) by writing to Zk with path version 36 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:33:51,808] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:51,853] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:33:51,852] INFO [broker-3-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:51,869] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:51,886] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:33:51,954] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:52,104] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:52,121] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:33:52,222] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:33:52,248] INFO [SocketServer brokerId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:52,338] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:33:52,357] INFO [SocketServer brokerId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:52,358] INFO [SocketServer brokerId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:52,401] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:52,401] INFO [SocketServer brokerId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:52,402] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:52,404] INFO Kafka startTimeMs: 1621704832370 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:52,451] INFO [SocketServer brokerId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:33:52,452] INFO [SocketServer brokerId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:33:52,411] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2021-05-22 18:33:52,469] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:52,475] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:52,475] INFO Kafka startTimeMs: 1621704832453 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:33:52,486] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2021-05-22 18:33:52,663] INFO [broker-5-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:33:52,806] INFO [broker-4-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:45:08,829] WARN Client session timed out, have not heard from server in 20996ms for sessionid 0x10000008ad30000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,026] WARN Client session timed out, have not heard from server in 20289ms for sessionid 0x10000008ad30003 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,038] INFO Client session timed out, have not heard from server in 20289ms for sessionid 0x10000008ad30003, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,054] WARN Client session timed out, have not heard from server in 22419ms for sessionid 0x10000008ad30001 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:08,829] WARN Client session timed out, have not heard from server in 16529ms for sessionid 0x10000008ad30004 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,059] INFO Client session timed out, have not heard from server in 16529ms for sessionid 0x10000008ad30004, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,059] INFO Client session timed out, have not heard from server in 22419ms for sessionid 0x10000008ad30001, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,068] WARN Client session timed out, have not heard from server in 13792ms for sessionid 0x10000008ad30002 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,070] INFO Client session timed out, have not heard from server in 13792ms for sessionid 0x10000008ad30002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,387] WARN Client session timed out, have not heard from server in 20769ms for sessionid 0x10000008ad30005 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:09,403] INFO Client session timed out, have not heard from server in 20769ms for sessionid 0x10000008ad30005, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:45:27,567] INFO Client session timed out, have not heard from server in 20996ms for sessionid 0x10000008ad30000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:50:13,993] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:13,999] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,017] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,017] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,030] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:50:14,031] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:50:14,031] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-05-22 18:50:14,031] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-05-22 18:50:14,053] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-05-22 18:50:14,092] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,093] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,094] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,094] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-05-22 18:50:14,094] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-05-22 18:50:14,110] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-05-22 18:50:14,163] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,163] INFO Server environment:host.name=rafael-pc (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,164] INFO Server environment:java.version=11.0.11 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,164] INFO Server environment:java.vendor=Ubuntu (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,164] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,165] INFO Server environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,167] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,167] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,168] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,168] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,168] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,168] INFO Server environment:os.version=5.8.0-53-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,169] INFO Server environment:user.name=rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,169] INFO Server environment:user.home=/home/rafael (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,169] INFO Server environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,169] INFO Server environment:os.memory.free=494MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,169] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,170] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,174] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,174] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,176] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-05-22 18:50:14,211] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-05-22 18:50:14,227] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 4 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:50:14,240] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-05-22 18:50:14,241] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:455)
	at java.base/sun.nio.ch.Net.bind(Net.java:447)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-05-22 18:50:25,920] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-05-22 18:50:27,010] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-05-22 18:50:27,168] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2021-05-22 18:50:27,179] INFO starting (kafka.server.KafkaServer)
[2021-05-22 18:50:27,181] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-05-22 18:50:27,250] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:50:27,271] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,271] INFO Client environment:host.name=rafael-pc (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,271] INFO Client environment:java.version=11.0.11 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,272] INFO Client environment:java.vendor=Ubuntu (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,272] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,277] INFO Client environment:java.class.path=/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/activation-1.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-cli-1.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-api-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-file-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-json-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-runtime-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/connect-transforms-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-core-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.25.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javassist-3.26.0-GA.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-client-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-common-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-hk2-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jersey-server-2.31.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-clients-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-raft-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/kafka-tools-2.7.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/log4j-1.2.17.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/lz4-java-1.7.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/maven-artifact-3.6.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/paranamer-2.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/reflections-0.9.12.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-library-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/scala-reflect-2.13.3.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/home/rafael/Desktop/TP2AS/kafka/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,279] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,280] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,280] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,281] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,281] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,281] INFO Client environment:os.version=5.8.0-53-generic (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,281] INFO Client environment:user.name=rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,281] INFO Client environment:user.home=/home/rafael (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,282] INFO Client environment:user.dir=/home/rafael/Desktop/TP2AS/kafka/kafka (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,282] INFO Client environment:os.memory.free=978MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,282] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,282] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,291] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35b74c5c (org.apache.zookeeper.ZooKeeper)
[2021-05-22 18:50:27,303] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-05-22 18:50:27,318] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:50:27,329] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:50:27,364] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:50:27,386] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:46432, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:50:27,432] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100000078250000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-05-22 18:50:27,438] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-05-22 18:50:27,669] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2021-05-22 18:50:28,166] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2021-05-22 18:50:28,170] INFO Cluster ID = COF0WAEkTNaeFUnG8ETA1Q (kafka.server.KafkaServer)
[2021-05-22 18:50:28,172] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-05-22 18:50:28,286] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:50:28,308] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 6
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-05-22 18:50:28,418] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:50:28,427] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:50:28,429] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:50:28,446] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-05-22 18:50:28,567] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2021-05-22 18:50:28,585] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2021-05-22 18:50:28,596] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2021-05-22 18:50:28,612] INFO Loaded 0 logs in 26ms. (kafka.log.LogManager)
[2021-05-22 18:50:28,651] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-05-22 18:50:28,657] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-05-22 18:50:30,690] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:50:30,693] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:50:30,696] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2021-05-22 18:50:30,699] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2021-05-22 18:50:30,802] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:50:30,892] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:30,894] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:30,894] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:30,913] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:30,952] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-05-22 18:50:30,957] INFO [broker-0-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:50:31,043] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-05-22 18:50:31,091] INFO Stat of the created znode at /brokers/ids/0 is: 806,806,1621705831077,1621705831077,1,0,0,72057596053618688,202,0,806
 (kafka.zk.KafkaZkClient)
[2021-05-22 18:50:31,092] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 806 (kafka.zk.KafkaZkClient)
[2021-05-22 18:50:31,262] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:31,290] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:31,297] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:31,390] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:50:31,406] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-05-22 18:50:31,476] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:36000,blockEndProducerId:36999) by writing to Zk with path version 37 (kafka.coordinator.transaction.ProducerIdManager)
[2021-05-22 18:50:31,543] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:50:31,547] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-05-22 18:50:31,576] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-05-22 18:50:31,711] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-05-22 18:50:31,794] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-05-22 18:50:31,811] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:50:31,839] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-05-22 18:50:31,849] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-05-22 18:50:31,858] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:50:31,858] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:50:31,858] INFO Kafka startTimeMs: 1621705831850 (org.apache.kafka.common.utils.AppInfoParser)
[2021-05-22 18:50:31,860] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-05-22 18:50:31,981] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2021-05-22 18:56:42,729] INFO Creating topic Sensor with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-05-22 18:56:42,779] INFO [KafkaApi-0] Auto creation of topic Sensor with 6 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2021-05-22 18:56:42,994] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-0, Sensor-5, Sensor-2, Sensor-3, Sensor-1, Sensor-4) (kafka.server.ReplicaFetcherManager)
[2021-05-22 18:56:43,071] INFO [Log partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-05-22 18:56:43,083] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-05-22 18:56:43,096] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2021-05-22 18:56:43,097] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2021-05-22 18:56:43,140] INFO [Log partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-05-22 18:56:43,144] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-05-22 18:56:43,145] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2021-05-22 18:56:43,145] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2021-05-22 18:56:43,186] INFO [Log partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-05-22 18:56:43,195] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-05-22 18:56:43,203] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2021-05-22 18:56:43,204] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2021-05-22 18:56:43,216] INFO [Log partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-05-22 18:56:43,220] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-05-22 18:56:43,220] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2021-05-22 18:56:43,220] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-05-22 18:56:43,237] INFO [Log partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-05-22 18:56:43,239] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-05-22 18:56:43,240] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2021-05-22 18:56:43,240] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2021-05-22 18:56:43,255] INFO [Log partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-05-22 18:56:43,263] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-05-22 18:56:43,264] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2021-05-22 18:56:43,264] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
